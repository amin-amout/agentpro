# LLM Configuration
LLM_API_TYPE=groq  # or local
LLM_API_URL=https://api.groq.com/openai/v1/chat/completions
LLM_API_KEY=your_api_key_here

# Model Configuration
DEFAULT_MODEL=mixtral-8x7b-32768  # for Groq
TEMPERATURE=0.7
MAX_TOKENS=4096

# Local LLM Configuration (if used)
LOCAL_LLM_URL=http://localhost:8000/v1/chat/completions